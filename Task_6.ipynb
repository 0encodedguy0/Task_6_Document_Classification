{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 6. Классификация новостей\n",
    "\n",
    "### Данные\n",
    "Данные в [архиве](https://drive.google.com/file/d/15o7fdxTgndoy6K-e7g8g1M2-bOOwqZPl/view?usp=sharing). В нём два файла:\n",
    "- `news_train.txt` тестовое множество\n",
    "- `news_test.txt` тренировочное множество\n",
    "\n",
    "С некоторых новостных сайтов были загружены тексты новостей за период  несколько лет, причем каждая новость принаделжит к какой-то рубрике: `science`, `style`, `culture`, `life`, `economics`, `business`, `travel`, `forces`, `media`, `sport`.\n",
    "\n",
    "В каждой строке файла содержится метка рубрики, заголовок новостной статьи и сам текст статьи, например:\n",
    "\n",
    ">    **sport**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею разгромила чехов**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею крупно об...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6.1 \n",
    "\n",
    "Обработать данные, получив для каждого текста набор токенов\n",
    "Обработать токены с помощью (один вариант из трех):\n",
    "\n",
    "- pymorphy2\n",
    "- русского [snowball стеммера](https://www.nltk.org/howto/stem.html)\n",
    "- [SentencePiece](https://github.com/google/sentencepiece) или [Huggingface Tokenizers](https://github.com/huggingface/tokenizers)\n",
    "    \n",
    "    \n",
    "## Задание 6.2\n",
    "\n",
    "Обучить word embeddings (fastText, word2vec, gloVe) на тренировочных данных. Можно использовать [gensim](https://radimrehurek.com/gensim/models/word2vec.html) . Продемонстрировать семантические ассоциации. \n",
    "\n",
    "## Задание 6.3\n",
    "\n",
    "Реализовать алгоритм классификации документа по категориям, посчитать точноть на тестовых данных, подобрать гиперпараметры. Метод векторизации выбрать произвольно - можно использовать $tf-idf$ с понижением размерности (см. scikit-learn), можно использовать обученные на предыдущем шаге векторные представления, можно использовать [предобученные модели](https://rusvectores.org/ru/models/). Имейте ввиду, что простое \"усреднение\" токенов в тексте скорее всего не даст положительных результатов. Нужно реализовать два алгоритмов из трех:\n",
    "- SVM\n",
    "- наивный байесовский классификатор\n",
    "- логистическая регрессия\n",
    "    \n",
    "\n",
    "## Задание 6.4* \n",
    "\n",
    "Реализуйте классификацию с помощью нейросетевых моделей. Например [RuBERT](http://docs.deeppavlov.ai/en/master/features/models/bert.html) или [ELMo](https://rusvectores.org/ru/models/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\msi\\anaconda3\\lib\\site-packages (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.manifold import TSNE\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('news_train.txt', sep=\"\\t\", header=None)\n",
    "test_data = pd.read_csv('news_test.txt', sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport</td>\n",
       "      <td>Овечкин пожертвовал детской хоккейной школе ав...</td>\n",
       "      <td>Нападающий «Вашингтон Кэпиталз» Александр Овеч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culture</td>\n",
       "      <td>Рекордно дорогую статую майя признали подделкой</td>\n",
       "      <td>Власти Мексики объявили подделкой статую майя,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>Samsung представила флагман в защищенном корпусе</td>\n",
       "      <td>Южнокорейская Samsung анонсировала защищенную ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>С футболиста «Спартака» сняли четырехматчевую ...</td>\n",
       "      <td>Контрольно-дисциплинарный комитет (КДК) РФС сн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media</td>\n",
       "      <td>Hopes &amp; Fears объединится с The Village</td>\n",
       "      <td>Интернет-издание Hopes &amp; Fears объявило о свое...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1  \\\n",
       "0    sport  Овечкин пожертвовал детской хоккейной школе ав...   \n",
       "1  culture    Рекордно дорогую статую майя признали подделкой   \n",
       "2  science   Samsung представила флагман в защищенном корпусе   \n",
       "3    sport  С футболиста «Спартака» сняли четырехматчевую ...   \n",
       "4    media            Hopes & Fears объединится с The Village   \n",
       "\n",
       "                                                   2  \n",
       "0  Нападающий «Вашингтон Кэпиталз» Александр Овеч...  \n",
       "1  Власти Мексики объявили подделкой статую майя,...  \n",
       "2  Южнокорейская Samsung анонсировала защищенную ...  \n",
       "3  Контрольно-дисциплинарный комитет (КДК) РФС сн...  \n",
       "4  Интернет-издание Hopes & Fears объявило о свое...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.rename(columns = {0: 'mark', 1: 'header', 2: 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.rename(columns = {0: 'mark', 1: 'header', 2: 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(SnowballStemmer.languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "приостанов\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem(\"приостановить\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, num):\n",
    "    newString = text.lower()\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = newString.replace('[', '')\n",
    "    newString = newString.replace(']', '')\n",
    "    newString = re.sub('»','', newString)\n",
    "    newString = re.sub('«','', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = re.sub(r'[,\"\\'-?:!;—%]', '', newString)\n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split()]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:\n",
    "            long_words.append(stemmer.stem(i))\n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['напада вашингтон кэпиталз александр овечкин переда детск хоккейн школ автомобил получен им посл окончан матч всех звезд национальн хоккейн лиг об эт сообща на официальн сайт лигиавтомобил honda accord был подар хоккеист по решен спонсор мероприят игрок нхл пожертвова машин спортивн школ nova cool cats special hockey inc котор располож штат вирджинияовечкин обща летн девочк ан шоб синдром даун котор занима эт школ явля поклонниц спортсм сентябр форвард пообеда вмест юн хоккеистк японск ресторанематч всех звезд нхл коламбус заверш побед команд джоната тэйвз над команд ник фолин со счет овечкин выступа за проигра коллект россиянин отмет трем результативн передач', 'власт мексик объяв подделк стат май прода на эт недел на аукцион париж за рекордн сумм миллион евр сообща agence франcепрессеминистерств иностра дел национальн институт антрополог истор выступ совместн заявлен утвержд что стату не относ ни одн из доколумбов культур центральн америк утвержда что произведен относ позднеклассическ период май однак учен не обнаруж стату характерн черт какойлиб конкретн культур тог временип все видим автор подделк пыта воспроизвест стил индейц май северовосток мексик однак размер стату положен ног фигур изображен обув для нег не характерн археолог алехандр кастил алехандр баутист вальдеспин заяв что изображен воин топор щит скор всег был созда недавн год посольств мексик уж уведом об эт власт франциисантиметров скульптур был част собран швейцарск бизнесм генр ло е куп анонимн коллекционер из европ лот стал сам дорог на аукцион drouot всег на тех торг был выруч миллион еврокак отмеча artdaily результат предпродажн экспертиз проведен мексиканск учен стал известн что из произведен из коллекц ло оказа подделк как образ сомнительн стату все же попа на торг не сообща', 'южнокорейск samsung анонсирова защищен верс сво флагма galaxy active об эт говор сообщен американск оператор at&t котор будет распространя нов устройствоматериа корпус смартфон выполн из высокопрочн пластик устройств получ сертификат защит ip эт означа что смартфон явля ударопрочн пылестойк такж выдерж погружен вод на глубин до метр длительн до минутп характеристик гаджет не сильн уступа последн флагман компан galaxy аппарат получ дюймов диспл quad hd super amoled битн восьмиядерн процессор exynos собствен производств samsung заметн отлич составля то что новинк не имеет сканер отпечатк пальц как galaxy однак батаре защищен смартфон бол емк миллиамперчасовустройств оснащ мегапиксельн основн камер мегапиксельн фронтальн широкоугольн объектив для бол удобн создан группов селф для хранен предоставл гигабайт внутрен памят работа смартфон под управлен android lollipop июн гаджет можн будет приобрест через сайт at&t ил ег магазин сша по цен без контракт долларовсамсунг сотруднича американск оператор уж трет год', 'контрольнодисциплинарн комитет рфс снял дисквалификац полузащитник московск спартак эйд макгид об эт сообща ри новост так образ ирландец сможет сыгра матч го тур чемпионат росс владикавказск алан ма кдк дисквалифицирова макгид на шест игр четыр матч наказан игрок получ за красн карточк игр го тур мордов ещ две встреч ирландец долж был пропуст за то что пнул микрофон возл пол показа неприличн жест болельщик ма апелляцион комитет рфс удовлетвор жалоб спартак отправ дел на повторн рассмотрен на внеочередн заседан кдк прошедш ма москв был принят решен снят четырехматчев дисквалификац наказан за оскорбительн действ был оставл сил однак ирландец уж пропуст две игр поэт сможет выйт на пол ближайш встреч сво командыматч спартак алан пройдет ма москв на стадион эдуард стрельцов случа побед краснобел гарантир себ участ лиг европ след сезон', 'интернетиздан hopes fears объяв сво слиян сайт the village официальн сообщен об эт появ на главн страниц сайт июл hopes fears объединя the village чтоб вмест двух сайт бизнес городск жизн стро одн мед котор рассказыва сам важн событ дня недел месяц объясня что он значат эт локальн повестк глобальн новостн истор говор обращенииматериал по тем октябр чаян опасен рокнроллсоздател look at media рассказа сво четверт проектет же отмеча что бизнестематик на котор специализирова порта h&f не пропадет ваш любим рубрик сериал клуб совет директор сохран общ почт то же сам но на друг домен друг бренд уточня редакцияоб сайт вход российск издательск дом look at media ид был основа год на дан момент ег состав сайт look at me городск интернетгазет the village мужск журна furfur сайт молод предпринимател hopes fears женск интернетжурна wonderzine']\n"
     ]
    }
   ],
   "source": [
    "cleaned_header_train = []\n",
    "cleaned_text_train = []\n",
    "\n",
    "for t in train_data['header']:\n",
    "    cleaned_header_train.append(clean_text(t, 0))\n",
    "\n",
    "for t in train_data['text']:\n",
    "    cleaned_text_train.append(clean_text(t, 0))\n",
    "\n",
    "print(cleaned_text_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mark</th>\n",
       "      <th>header</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport</td>\n",
       "      <td>овечкин пожертвова детск хоккейн школ автомобил</td>\n",
       "      <td>напада вашингтон кэпиталз александр овечкин пе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culture</td>\n",
       "      <td>рекордн дорог стат май призна подделк</td>\n",
       "      <td>власт мексик объяв подделк стат май прода на э...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>samsung представ флагма защищен корпус</td>\n",
       "      <td>южнокорейск samsung анонсирова защищен верс св...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>футболист спартак снял четырехматчев дисквалиф...</td>\n",
       "      <td>контрольнодисциплинарн комитет рфс снял дисква...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media</td>\n",
       "      <td>hopes fears объедин the village</td>\n",
       "      <td>интернетиздан hopes fears объяв сво слиян сайт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>life</td>\n",
       "      <td>составл рейтинг лучш европейск пляж год</td>\n",
       "      <td>опубликова рейтинг лучш европейск пляж год топ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>media</td>\n",
       "      <td>сноб объясн причин смен формат</td>\n",
       "      <td>генеральн директор сноб мед марин геворкя объя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>economics</td>\n",
       "      <td>минфин предлож штрафова за биткоин на тысяч рубл</td>\n",
       "      <td>минфин разработа законопроект устанавлива штра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>life</td>\n",
       "      <td>мэл гибсон заплат бывш подруг тысяч доллар</td>\n",
       "      <td>актер режиссер мэл гибсон выплат сво бывш подр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>media</td>\n",
       "      <td>ещ на двух лин московск метр заработа wifi</td>\n",
       "      <td>на серпуховскотимирязевск бутовск лин московск...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mark                                             header  \\\n",
       "0          sport    овечкин пожертвова детск хоккейн школ автомобил   \n",
       "1        culture              рекордн дорог стат май призна подделк   \n",
       "2        science             samsung представ флагма защищен корпус   \n",
       "3          sport  футболист спартак снял четырехматчев дисквалиф...   \n",
       "4          media                    hopes fears объедин the village   \n",
       "...          ...                                                ...   \n",
       "14995       life            составл рейтинг лучш европейск пляж год   \n",
       "14996      media                     сноб объясн причин смен формат   \n",
       "14997  economics   минфин предлож штрафова за биткоин на тысяч рубл   \n",
       "14998       life         мэл гибсон заплат бывш подруг тысяч доллар   \n",
       "14999      media         ещ на двух лин московск метр заработа wifi   \n",
       "\n",
       "                                                    text  \n",
       "0      напада вашингтон кэпиталз александр овечкин пе...  \n",
       "1      власт мексик объяв подделк стат май прода на э...  \n",
       "2      южнокорейск samsung анонсирова защищен верс св...  \n",
       "3      контрольнодисциплинарн комитет рфс снял дисква...  \n",
       "4      интернетиздан hopes fears объяв сво слиян сайт...  \n",
       "...                                                  ...  \n",
       "14995  опубликова рейтинг лучш европейск пляж год топ...  \n",
       "14996  генеральн директор сноб мед марин геворкя объя...  \n",
       "14997  минфин разработа законопроект устанавлива штра...  \n",
       "14998  актер режиссер мэл гибсон выплат сво бывш подр...  \n",
       "14999  на серпуховскотимирязевск бутовск лин московск...  \n",
       "\n",
       "[15000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marks = train_data.mark.values\n",
    "header = cleaned_header_train\n",
    "text = cleaned_text_train\n",
    "columns = ['mark', 'header', 'text']\n",
    "arr = []\n",
    "for i in range(len(marks)):\n",
    "    arr.append([marks[i], header[i], text[i]])\n",
    "new_df = pd.DataFrame(arr, columns=columns)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec()\n",
    "titles= new_df.header.apply(lambda x : x.split(\" \")).values\n",
    "sentences = new_df.text.apply(lambda x : x.split(\" \")).values\n",
    "model.build_vocab(titles + sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43780600, 50385420)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(titles + sentences, total_examples=len(sentences), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('хокке', 0.5714800357818604),\n",
       " ('мутк', 0.5538972020149231),\n",
       " ('баскетбол', 0.53962242603302),\n",
       " ('атлетик', 0.5288175940513611),\n",
       " ('федерац', 0.506080150604248),\n",
       " ('фигурн', 0.4973459541797638),\n",
       " ('футбол', 0.49576252698898315),\n",
       " ('туризм', 0.4894735515117645),\n",
       " ('фигурист', 0.4877971112728119),\n",
       " ('катан', 0.4876573383808136)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['спорт'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('баскетбол', 0.682264506816864),\n",
       " ('хокке', 0.6673117280006409),\n",
       " ('атлетик', 0.6339982151985168),\n",
       " ('биатлон', 0.6325415968894958),\n",
       " ('фигурн', 0.5943467020988464),\n",
       " ('теннис', 0.5931338667869568),\n",
       " ('хокк', 0.5840518474578857),\n",
       " ('волейбол', 0.5644078850746155),\n",
       " ('мутк', 0.5626018643379211),\n",
       " ('катан', 0.5538978576660156)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['спорт', 'футбол'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('lr_clf', LogisticRegression(random_state=42))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_ppl_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr_clf', LogisticRegression(random_state=42))])\n",
    "lr_ppl_clf.fit(train_data.text, train_data.mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.23      0.78      0.36        27\n",
      "     culture       0.92      0.92      0.92       427\n",
      "   economics       0.91      0.82      0.87       473\n",
      "      forces       0.88      0.83      0.85       261\n",
      "        life       0.90      0.81      0.86       461\n",
      "       media       0.88      0.84      0.86       422\n",
      "     science       0.86      0.89      0.88       451\n",
      "       sport       0.97      0.97      0.97       421\n",
      "       style       0.71      1.00      0.83        37\n",
      "      travel       0.37      1.00      0.54        20\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.76      0.89      0.79      3000\n",
      "weighted avg       0.89      0.87      0.88      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_lr = lr_ppl_clf.predict(test_data.text)\n",
    "print(metrics.classification_report(predicted_lr, test_data.mark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('lr_clf',\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             param_grid={'lr_clf__C': [10, 1.0, 0.1, 0.01, 0.001]})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_params = {'lr_clf__C': [10, 1.0, 0.1, 0.01, 0.001],\n",
    "            }\n",
    "lr_grid = GridSearchCV(estimator=lr_ppl_clf, param_grid=lr_params)\n",
    "lr_grid.fit(train_data.text, train_data.mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr_clf__C': 10} 0.8711333333333334\n"
     ]
    }
   ],
   "source": [
    "print(lr_grid.best_params_, lr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.48      0.78      0.59        55\n",
      "     culture       0.93      0.93      0.93       428\n",
      "   economics       0.92      0.87      0.89       448\n",
      "      forces       0.89      0.83      0.86       265\n",
      "        life       0.92      0.85      0.88       446\n",
      "       media       0.88      0.87      0.87       408\n",
      "     science       0.86      0.90      0.88       449\n",
      "       sport       0.97      0.98      0.98       419\n",
      "       style       0.81      0.95      0.88        44\n",
      "      travel       0.65      0.92      0.76        38\n",
      "\n",
      "    accuracy                           0.89      3000\n",
      "   macro avg       0.83      0.89      0.85      3000\n",
      "weighted avg       0.90      0.89      0.89      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_lr_grid = lr_grid.predict(test_data.text)\n",
    "print(metrics.classification_report(predicted_lr_grid, test_data.mark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('mnb_clf', MultinomialNB())])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_ppl_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('mnb_clf', naive_bayes.MultinomialNB())])\n",
    "mnb_ppl_clf.fit(train_data.text, train_data.mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.00      0.00      0.00         0\n",
      "     culture       0.92      0.87      0.89       450\n",
      "   economics       0.97      0.66      0.78       629\n",
      "      forces       0.51      0.93      0.65       134\n",
      "        life       0.77      0.87      0.82       368\n",
      "       media       0.87      0.73      0.79       480\n",
      "     science       0.87      0.81      0.84       503\n",
      "       sport       0.99      0.96      0.97       436\n",
      "       style       0.00      0.00      0.00         0\n",
      "      travel       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.81      3000\n",
      "   macro avg       0.59      0.58      0.57      3000\n",
      "weighted avg       0.89      0.81      0.84      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted_mnb = mnb_ppl_clf.predict(test_data.text)\n",
    "print(metrics.classification_report(predicted_mnb, test_data.mark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('mnb_clf', MultinomialNB())]),\n",
       "             param_grid={'mnb_clf__alpha': [0, 1]})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'mnb_clf__alpha': [0, 1]}\n",
    "mnb_grid = GridSearchCV(mnb_ppl_clf, parameters)\n",
    "mnb_grid.fit(train_data.text, train_data.mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mnb_clf__alpha': 0} 0.8132666666666666\n"
     ]
    }
   ],
   "source": [
    "print(mnb_grid.best_params_, mnb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.21      0.61      0.31        31\n",
      "     culture       0.89      0.85      0.87       445\n",
      "   economics       0.89      0.82      0.85       464\n",
      "      forces       0.76      0.81      0.78       232\n",
      "        life       0.83      0.79      0.81       438\n",
      "       media       0.81      0.72      0.76       454\n",
      "     science       0.83      0.80      0.82       480\n",
      "       sport       0.94      0.99      0.96       402\n",
      "       style       0.56      0.91      0.69        32\n",
      "      travel       0.41      1.00      0.58        22\n",
      "\n",
      "    accuracy                           0.82      3000\n",
      "   macro avg       0.71      0.83      0.74      3000\n",
      "weighted avg       0.84      0.82      0.83      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_mnb_grid = mnb_grid.predict(test_data.text)\n",
    "print(metrics.classification_report(predicted_mnb_grid, test_data.mark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
